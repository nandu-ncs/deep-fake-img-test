{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO!!\n",
      "Preparing the training & validation data...\n",
      "WARNING:tensorflow:From <ipython-input-1-0b8773300f9c>:205: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\input.py:372: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\input.py:318: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-1-0b8773300f9c>:220: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From <ipython-input-1-0b8773300f9c>:222: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "Found 385198 training images, and 10000 validation images...\n",
      "Preparing the training model with learning rate = 0.00010...\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\function.py:987: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "[L-1] Build 0th residual block 0 with 64 channels\n",
      "[L-2] Build 0th connection layer 1 from 64 to 96 channels\n",
      "[L-3] Build 1th residual block 0 with 96 channels\n",
      "[L-4] Build 1th residual block 1 with 96 channels\n",
      "[L-5] Build 1th residual block 2 with 96 channels\n",
      "[L-6] Build 1th connection layer 3 from 96 to 128 channels\n",
      "[L-7] Build 2th residual block 0 with 128 channels\n",
      "[L-8] Build 2th residual block 1 with 128 channels\n",
      "[L-9] Build 2th residual block 2 with 128 channels\n",
      "[L-10] Build 0th residual block 0 with 64 channels\n",
      "[L-11] Build 0th connection layer 1 from 64 to 96 channels\n",
      "[L-12] Build 1th residual block 0 with 96 channels\n",
      "[L-13] Build 1th residual block 1 with 96 channels\n",
      "[L-14] Build 1th residual block 2 with 96 channels\n",
      "[L-15] Build 1th connection layer 3 from 96 to 128 channels\n",
      "[L-16] Build 2th residual block 0 with 128 channels\n",
      "[L-17] Build 2th residual block 1 with 128 channels\n",
      "[L-18] Build 2th residual block 2 with 128 channels\n",
      "Layer33's shape [128, 3, 3, 128]\n",
      "Layer55's shape [128, 3, 3, 128]\n",
      "[L-1] Build 0th residual block 0 with 64 channels\n",
      "[L-2] Build 0th connection layer 1 from 64 to 96 channels\n",
      "[L-3] Build 1th residual block 0 with 96 channels\n",
      "[L-4] Build 1th residual block 1 with 96 channels\n",
      "[L-5] Build 1th residual block 2 with 96 channels\n",
      "[L-6] Build 1th connection layer 3 from 96 to 128 channels\n",
      "[L-7] Build 2th residual block 0 with 128 channels\n",
      "[L-8] Build 2th residual block 1 with 128 channels\n",
      "[L-9] Build 2th residual block 2 with 128 channels\n",
      "[L-10] Build 0th residual block 0 with 64 channels\n",
      "[L-11] Build 0th connection layer 1 from 64 to 96 channels\n",
      "[L-12] Build 1th residual block 0 with 96 channels\n",
      "[L-13] Build 1th residual block 1 with 96 channels\n",
      "[L-14] Build 1th residual block 2 with 96 channels\n",
      "[L-15] Build 1th connection layer 3 from 96 to 128 channels\n",
      "[L-16] Build 2th residual block 0 with 128 channels\n",
      "[L-17] Build 2th residual block 1 with 128 channels\n",
      "[L-18] Build 2th residual block 2 with 128 channels\n",
      "Layer33's shape [1000, 3, 3, 128]\n",
      "Layer55's shape [1000, 3, 3, 128]\n",
      "We are going to train fake detector using ResNet based on triplet loss!!!\n",
      "Iter=10240/epoch=0, Loss=1.522356, Triplet loss=1.972600, Training Accuracy=0.437500, lr=0.000100\n",
      "Iter=20480/epoch=0, Loss=1.484721, Triplet loss=1.915924, Training Accuracy=0.476562, lr=0.000100\n",
      "Iter=30720/epoch=0, Loss=1.510159, Triplet loss=1.972857, Training Accuracy=0.484375, lr=0.000100\n",
      "Iter=40960/epoch=0, Loss=1.609030, Triplet loss=1.904916, Training Accuracy=0.453125, lr=0.000100\n",
      "Iter=51200/epoch=0, Loss=1.255448, Triplet loss=1.959348, Training Accuracy=0.539062, lr=0.000100\n",
      "Iter=61440/epoch=0, Loss=1.592643, Triplet loss=1.872028, Training Accuracy=0.429688, lr=0.000100\n",
      "Iter=71680/epoch=0, Loss=1.434455, Triplet loss=1.834027, Training Accuracy=0.515625, lr=0.000100\n",
      "Iter=81920/epoch=0, Loss=1.445113, Triplet loss=1.960574, Training Accuracy=0.492188, lr=0.000100\n",
      "Iter=92160/epoch=0, Loss=1.537200, Triplet loss=1.905745, Training Accuracy=0.421875, lr=0.000100\n",
      "Iter=102400/epoch=0, Loss=1.765692, Triplet loss=1.761550, Training Accuracy=0.382812, lr=0.000100\n",
      "Iter=112640/epoch=0, Loss=1.643985, Triplet loss=1.978239, Training Accuracy=0.421875, lr=0.000100\n",
      "Iter=122880/epoch=0, Loss=1.557447, Triplet loss=1.860663, Training Accuracy=0.476562, lr=0.000100\n",
      "Iter=133120/epoch=0, Loss=1.332581, Triplet loss=2.015627, Training Accuracy=0.476562, lr=0.000100\n",
      "Iter=143360/epoch=0, Loss=1.650537, Triplet loss=1.949066, Training Accuracy=0.429688, lr=0.000100\n",
      "Iter=153600/epoch=0, Loss=1.493748, Triplet loss=1.913629, Training Accuracy=0.445312, lr=0.000100\n",
      "Iter=163840/epoch=0, Loss=1.581652, Triplet loss=1.890274, Training Accuracy=0.421875, lr=0.000100\n",
      "Iter=174080/epoch=0, Loss=1.470141, Triplet loss=1.873298, Training Accuracy=0.460938, lr=0.000100\n",
      "Iter=184320/epoch=0, Loss=1.502211, Triplet loss=2.004305, Training Accuracy=0.421875, lr=0.000100\n",
      "Iter=194560/epoch=0, Loss=1.554497, Triplet loss=1.935095, Training Accuracy=0.437500, lr=0.000100\n",
      "Iter=204800/epoch=0, Loss=1.453041, Triplet loss=1.976973, Training Accuracy=0.500000, lr=0.000100\n",
      "> d:\\research\\fakefacedetection\\fake-face-images-detection\\utils.py(384)batchsalwrite()\n",
      "-> im1 = np.asarray(to_range(image[i,:,:,:]), np.float)\n",
      "(Pdb) n\n",
      "> d:\\research\\fakefacedetection\\fake-face-images-detection\\utils.py(385)batchsalwrite()\n",
      "-> scipy.misc.imsave(\"%s_Original_%d_%d-%d.jpg\"%(path, i, tis[i], vis[i]), np.asarray(im1, np.uint8))\n",
      "(Pdb) im1\n",
      "array([[[  55.,   50.,   46.],\n",
      "        [ 127.,  126.,  123.],\n",
      "        [ 219.,  222.,  222.],\n",
      "        ..., \n",
      "        [ 167.,  146.,  125.],\n",
      "        [ 151.,  129.,  116.],\n",
      "        [ 148.,  122.,  120.]],\n",
      "\n",
      "       [[ 115.,  111.,  107.],\n",
      "        [ 193.,  193.,  190.],\n",
      "        [ 243.,  245.,  245.],\n",
      "        ..., \n",
      "        [ 167.,  148.,  128.],\n",
      "        [ 173.,  151.,  138.],\n",
      "        [ 134.,  108.,  106.]],\n",
      "\n",
      "       [[ 112.,  110.,  106.],\n",
      "        [ 233.,  232.,  230.],\n",
      "        [ 238.,  242.,  242.],\n",
      "        ..., \n",
      "        [ 132.,  114.,   94.],\n",
      "        [ 167.,  147.,  134.],\n",
      "        [ 161.,  136.,  134.]],\n",
      "\n",
      "       ..., \n",
      "       [[ 164.,  161.,  154.],\n",
      "        [ 167.,  164.,  156.],\n",
      "        [ 185.,  184.,  177.],\n",
      "        ..., \n",
      "        [ 131.,  108.,   94.],\n",
      "        [ 132.,  111.,   95.],\n",
      "        [ 131.,  110.,   91.]],\n",
      "\n",
      "       [[ 169.,  169.,  163.],\n",
      "        [ 192.,  192.,  187.],\n",
      "        [ 166.,  169.,  162.],\n",
      "        ..., \n",
      "        [ 125.,  100.,   86.],\n",
      "        [ 125.,  103.,   86.],\n",
      "        [ 132.,  108.,   87.]],\n",
      "\n",
      "       [[ 170.,  171.,  166.],\n",
      "        [ 193.,  195.,  190.],\n",
      "        [ 161.,  165.,  160.],\n",
      "        ..., \n",
      "        [ 124.,   98.,   83.],\n",
      "        [ 142.,  119.,  102.],\n",
      "        [ 125.,  100.,   77.]]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pdb) im1.shape\n",
      "(64, 64, 3)\n",
      "(Pdb) sal1 = np.asarray(sal[i,:,:], np.float)*255\n",
      "(Pdb) sal1.shape\n",
      "(3, 3, 256)\n",
      "(Pdb) np.expand_dims(sal1, 2)\n",
      "array([[[[  4859.36213493,  16374.53029633,   1167.02402115, ...,\n",
      "           10145.25278091, -18254.26620483,   1251.73612833]],\n",
      "\n",
      "        [[ 18276.29116058,  12065.11550903, -18452.304039  , ...,\n",
      "           10206.41332626,  -7563.0854702 , -12116.6409874 ]],\n",
      "\n",
      "        [[-11992.75474548,  -5448.97181511, -17007.38445282, ...,\n",
      "            1695.36822081, -11728.76169205,  24378.36536407]]],\n",
      "\n",
      "\n",
      "       [[[  2158.5733366 ,  26035.4101181 , -23986.69624329, ...,\n",
      "            9963.58142853, -22692.62844086, -11493.4588623 ]],\n",
      "\n",
      "        [[  9679.3756485 ,  29114.11800385, -35017.83920288, ...,\n",
      "           19175.54008484, -12403.46735001,   4572.18169212]],\n",
      "\n",
      "        [[ -9315.41913986,  -4578.37906837, -14253.8146019 , ...,\n",
      "           12850.052948  ,    593.01520944,  -2468.49297523]]],\n",
      "\n",
      "\n",
      "       [[[ -1371.22263193,  14628.630867  ,   6323.89620781, ...,\n",
      "           28305.68481445,   1050.41502714,    935.92479944]],\n",
      "\n",
      "        [[-11260.70171356,  -1691.86961174, -19437.93685913, ...,\n",
      "            7335.89438438,  19667.57926941,  -4474.4662571 ]],\n",
      "\n",
      "        [[-15202.31472015,  22091.11816406, -29625.69580078, ...,\n",
      "           28886.50474548, -19179.8085022 ,   -997.37248778]]]])\n",
      "(Pdb) np.expand_dims(sal1, 2).shape\n",
      "(3, 3, 1, 256)\n",
      "(Pdb) sal.shape\n",
      "(1000, 3, 3, 256)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, pdb\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import threading\n",
    "import time\n",
    "from sklearn import metrics\n",
    "import utils\n",
    "global n_classes\n",
    "import triplet_loss as tri\n",
    "import os.path\n",
    "\n",
    "\n",
    "'''\n",
    "#===========================================================================\n",
    "Parameters:\n",
    "        TRAIN_WO_SPEC_GAN: Excluding GAN. E.f. progressGAN means We dont include progressGAN for tranining phase\n",
    "        n_classes: Number of classes (2 for now. one for fake and one for real)\n",
    "        data_dir:  The path to the file list directory\n",
    "        image_dir: The path to the images directory (if the image list is stored in absoluate path, set this to './')\n",
    "        margin:    Marginal value in triplet loss function\n",
    "Data Preparation\n",
    "        All training image list should put on the subfolder 'data' named by train_wo_[TRAIN_WO_SPEC_GAN].txt, wheere\n",
    "        the text file should have image path with its label (which GAN) such that \n",
    "        image_path1 0\n",
    "        image_path2 1\n",
    "        image_path3 5\n",
    "        image_path4 0\n",
    "        The data list in validation set is the same structure with training set.\n",
    "#===========================================================================\n",
    "'''\n",
    "TRAIN_WO_SPEC_GAN = 'progressGAN'                         \n",
    "n_classes = 2\n",
    "data_dir = '../../DCGAN-LSGAN-WGAN-WGAN-GP-Tensorflow/data/'\n",
    "image_dir = '../../DCGAN-LSGAN-WGAN-WGAN-GP-Tensorflow/'\n",
    "batch_size = 128\n",
    "display_step = 80\n",
    "learning_rate = tf.placeholder(tf.float32)      # Learning rate to be fed\n",
    "lr = 1e-4     \n",
    "margin = 0.8\n",
    "\n",
    "#========================Mode basic components============================\n",
    "def activation(x,name=\"activation\"):\n",
    "    return tf.nn.swish(x, name=name)\n",
    "    \n",
    "def conv2d(name, l_input, w, b, s, p):\n",
    "    l_input = tf.nn.conv2d(l_input, w, strides=[1,s,s,1], padding=p, name=name)\n",
    "    l_input = l_input+b\n",
    "\n",
    "    return l_input\n",
    "\n",
    "def batchnorm(conv, isTraining, name='bn'):\n",
    "    return tf.layers.batch_normalization(conv, training=isTraining, name=\"bn\"+name)\n",
    "\n",
    "def initializer(in_filters, out_filters, name, k_size=3):\n",
    "    w1 = tf.get_variable(name+\"W\", [k_size, k_size, in_filters, out_filters], initializer=tf.truncated_normal_initializer())\n",
    "    b1 = tf.get_variable(name+\"B\", [out_filters], initializer=tf.truncated_normal_initializer())\n",
    "    return w1, b1\n",
    "  \n",
    "def residual_block(in_x, in_filters, out_filters, stride, isDownSampled, name, isTraining, k_size=3):\n",
    "    global ema_gp\n",
    "    # first convolution layer\n",
    "    if isDownSampled:\n",
    "      in_x = tf.nn.avg_pool(in_x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "      \n",
    "    x = batchnorm(in_x, isTraining, name=name+'FirstBn')\n",
    "    x = activation(x)\n",
    "    w1, b1 = initializer(in_filters, in_filters, name+\"first_res\", k_size=k_size)\n",
    "    x = conv2d(name+'r1', x, w1, b1, 1, \"SAME\")\n",
    "\n",
    "    # second convolution layer\n",
    "    x = batchnorm(x, isTraining, name=name+'SecondBn')\n",
    "    x = activation(x)\n",
    "    w2, b2 = initializer(in_filters, out_filters, name+\"Second_res\",k_size=k_size)\n",
    "    x = conv2d(name+'r2', x, w2, b2, 1, \"SAME\")\n",
    "    \n",
    "    if in_filters != out_filters:\n",
    "        difference = out_filters - in_filters\n",
    "        left_pad = difference // 2\n",
    "        right_pad = difference - left_pad\n",
    "        identity = tf.pad(in_x, [[0, 0], [0, 0], [0, 0], [left_pad, right_pad]])\n",
    "        return x + identity\n",
    "    else:\n",
    "        return in_x + x\n",
    "\n",
    "\n",
    "'''\n",
    "#===========================================================================\n",
    "Network architecture based on ResNet\n",
    "#===========================================================================\n",
    "'''      \n",
    "def ResNet(_X, isTraining):\n",
    "    global n_classes\n",
    "    w1 = tf.get_variable(\"initWeight\", [7, 7, 3, 64], initializer=tf.truncated_normal_initializer())\n",
    "    b1 = tf.get_variable(\"initBias\", [64], initializer=tf.truncated_normal_initializer())\n",
    "    initx = conv2d('conv1', _X, w1, b1, 4, \"VALID\")\n",
    "    \n",
    "    filters_num = [64,96,128]\n",
    "    block_num = [2,4,3]\n",
    "    l_cnt = 1\n",
    "    x = initx\n",
    "    \n",
    "    # ============Feature extraction network with kernel size 3x3============\n",
    "    \n",
    "    for i in range(len(filters_num)):\n",
    "        for j in range(block_num[i]):\n",
    "          \n",
    "            if ((j==block_num[i]-1) & (i<len(filters_num)-1)):\n",
    "                x = residual_block(x, filters_num[i], filters_num[i+1], 2, True, 'ResidualBlock%d'%(l_cnt), isTraining)\n",
    "                print('[L-%d] Build %dth connection layer %d from %d to %d channels' % (l_cnt, i, j, filters_num[i], filters_num[i+1]))\n",
    "            else:\n",
    "                x = residual_block(x, filters_num[i], filters_num[i], 1, False, 'ResidualBlock%d'%(l_cnt), isTraining)\n",
    "                print('[L-%d] Build %dth residual block %d with %d channels' % (l_cnt,i, j, filters_num[i]))\n",
    "            l_cnt +=1\n",
    "    \n",
    "    layer_33 = x\n",
    "    x = initx\n",
    "    \n",
    "    # ============Feature extraction network with kernel size 5x5============\n",
    "    for i in range(len(filters_num)):\n",
    "        for j in range(block_num[i]):\n",
    "          \n",
    "            if ((j==block_num[i]-1) & (i<len(filters_num)-1)):\n",
    "                x = residual_block(x, filters_num[i], filters_num[i+1], 2, True, 'Residual5Block%d'%(l_cnt), isTraining, k_size=5)\n",
    "                print('[L-%d] Build %dth connection layer %d from %d to %d channels' % (l_cnt, i, j, filters_num[i], filters_num[i+1]))\n",
    "            else:\n",
    "                x = residual_block(x, filters_num[i], filters_num[i], 1, False, 'Residual5Block%d'%(l_cnt), isTraining, k_size=5)\n",
    "                print('[L-%d] Build %dth residual block %d with %d channels' % (l_cnt,i, j, filters_num[i]))\n",
    "            l_cnt +=1\n",
    "    layer_55 = x\n",
    "    print(\"Layer33's shape\", layer_33.get_shape().as_list())\n",
    "    print(\"Layer55's shape\", layer_55.get_shape().as_list())\n",
    "\n",
    "    x = tf.concat([layer_33, layer_55], 3)\n",
    "    \n",
    "    # ============ Classifier Learning============\n",
    "    \n",
    "    x_shape = x.get_shape().as_list()\n",
    "    dense1 = x_shape[1]*x_shape[2]*x_shape[3]\n",
    "    W = tf.get_variable(\"featW\", [dense1, 128], initializer=tf.truncated_normal_initializer())\n",
    "    b = tf.get_variable(\"featB\", [128], initializer=tf.truncated_normal_initializer())\n",
    "    dense1 = tf.reshape(x, [-1, dense1])\n",
    "    feat = tf.nn.softmax(tf.matmul(dense1, W) + b)\n",
    "    \n",
    "    with tf.variable_scope('Final'):\n",
    "        x = batchnorm(x, isTraining, name='FinalBn')\n",
    "        x = activation(x)\n",
    "        wo, bo=initializer(filters_num[-1]*2, n_classes, \"FinalOutput\")\n",
    "        x = conv2d('final', x, wo, bo, 1, \"SAME\")\n",
    "        saliency = tf.argmax(x, 3)\n",
    "        x=tf.reduce_mean(x, [1, 2])\n",
    "\n",
    "        W = tf.get_variable(\"FinalW\", [n_classes, n_classes], initializer=tf.truncated_normal_initializer())\n",
    "        b = tf.get_variable(\"FinalB\", [n_classes], initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "        out = tf.matmul(x, W) + b\n",
    "                            \n",
    "\n",
    "    return out, feat, saliency\n",
    "\n",
    "\n",
    "#==========================================================================\n",
    "#=============Reading data in multithreading manner========================\n",
    "#==========================================================================\n",
    "def read_labeled_image_list(image_list_file, training_img_dir):\n",
    "    f = open(image_list_file, 'r')\n",
    "    filenames = []\n",
    "    labels = []\n",
    "\n",
    "    for line in f:\n",
    "        filename, label = line[:-1].split(' ')\n",
    "        filename = training_img_dir+filename\n",
    "        filenames.append(filename)\n",
    "        labels.append(int(label))\n",
    "        \n",
    "    return filenames, labels\n",
    "    \n",
    "    \n",
    "def read_images_from_disk(input_queue, size1=64):\n",
    "    label = input_queue[1]\n",
    "    fn=input_queue[0]\n",
    "    file_contents = tf.read_file(input_queue[0])\n",
    "    example = tf.image.decode_jpeg(file_contents, channels=3)\n",
    "    \n",
    "    #example = tf.image.decode_png(file_contents, channels=3, name=\"dataset_image\") # png fo rlfw\n",
    "    example=tf.image.resize_images(example, [size1,size1])\n",
    "    return example, label, fn\n",
    "    \n",
    "def setup_inputs(sess, filenames, training_img_dir, image_size=64, crop_size=64, isTest=False, batch_size=128):\n",
    "    \n",
    "    # Read each image file\n",
    "    image_list, label_list = read_labeled_image_list(filenames, training_img_dir)\n",
    "\n",
    "    images = tf.cast(image_list, tf.string)\n",
    "    labels = tf.cast(label_list, tf.int64)\n",
    "     # Makes an input queue\n",
    "    if isTest is False:\n",
    "        isShuffle = True\n",
    "        numThr = 4\n",
    "    else:\n",
    "        isShuffle = False\n",
    "        numThr = 1\n",
    "        \n",
    "    input_queue = tf.train.slice_input_producer([images, labels], shuffle=isShuffle)\n",
    "    image, y,fn = read_images_from_disk(input_queue)\n",
    "\n",
    "    channels = 3\n",
    "    image.set_shape([None, None, channels])\n",
    "        \n",
    "    # Crop and other random augmentations\n",
    "    if isTest is False:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_saturation(image, .95, 1.05)\n",
    "        image = tf.image.random_brightness(image, .05)\n",
    "        image = tf.image.random_contrast(image, .95, 1.05)\n",
    "        \n",
    "    image = tf.cast(image, tf.float32)/255.0\n",
    "    \n",
    "    image, y,fn = tf.train.batch([image, y, fn], batch_size=batch_size, capacity=batch_size*3, num_threads=numThr, name='labels_and_images')\n",
    "\n",
    "    tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "    return image, y, fn, len(label_list)\n",
    "\n",
    "'''\n",
    "Maia training function:\n",
    "\n",
    "\n",
    "'''\n",
    "if not os.path.isdir('logs'):\n",
    "    os.mkdir('logs')\n",
    "if not os.path.isdir('saliency_img'):\n",
    "    os.mkdir('saliency_img')\n",
    "if not os.path.isdir('logs/pair'):\n",
    "    os.mkdir('logs/pair')\n",
    "if not os.path.isdir('logs/pair/%s/'%(TRAIN_WO_SPEC_GAN)):\n",
    "    os.mkdir('logs/pair/%s/'%(TRAIN_WO_SPEC_GAN))\n",
    "\n",
    "                   # Learning rate start\n",
    "tst = tf.placeholder(tf.bool)\n",
    "iter = tf.placeholder(tf.int32)\n",
    "print('GO!!')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Setup the tensorflow...\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "print(\"Preparing the training & validation data...\")\n",
    "pth1 = os.path.join(data_dir, \"train_wo_%s.txt\"%(TRAIN_WO_SPEC_GAN))\n",
    "train_data, train_labels, filelist1, glen1 = setup_inputs(sess, pth1, image_dir, batch_size=batch_size)\n",
    "pth2 = os.path.join(data_dir, \"val_wo_%s.txt\"%(TRAIN_WO_SPEC_GAN))\n",
    "val_data, val_labels, filelist2, tlen1 = setup_inputs(sess,pth2, image_dir, batch_size=1000,isTest=True)\n",
    "print(\"Found %d training images, and %d validation images...\" % (glen1, tlen1))\n",
    "\n",
    "max_iter = glen1*15\n",
    "print(\"Preparing the training model with learning rate = %.5f...\" % (lr))\n",
    "\n",
    "# Initialize the model for training set and validation sets\n",
    "with tf.variable_scope(\"ResNet\") as scope:\n",
    "    pred, feat,_ = ResNet(train_data, True)\n",
    "    scope.reuse_variables()\n",
    "    valpred, _, saliency = ResNet(val_data, False)\n",
    "\n",
    "\n",
    "# Forming the triplet loss by hard-triplet sampler  \n",
    "with tf.name_scope('Triplet_loss'):\n",
    "    \n",
    "    sialoss = tri.batch_hard_triplet_loss(train_labels, feat, margin, squared=False)\n",
    "\n",
    "# Forming the cross-entropy loss and accuracy for classifier learning\n",
    "with tf.name_scope('Loss_and_Accuracy'):\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        t_vars=tf.trainable_variables() \n",
    "        #t_vars=[var for var in t_vars if 'Final']\n",
    "        cost = tf.losses.sparse_softmax_cross_entropy(labels=train_labels, logits=pred)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost, var_list=t_vars)\n",
    "        sia_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(sialoss)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), train_labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    correct_prediction2 = tf.equal(tf.argmax(valpred, 1), val_labels)\n",
    "    accuracy2 = tf.reduce_mean(tf.cast(correct_prediction2, tf.float32))\n",
    "\n",
    "  \n",
    "tf.summary.scalar(\"Triplet_loss\", sialoss)\n",
    "tf.summary.scalar('Loss', cost)\n",
    "tf.summary.scalar('Training_Accuracy', accuracy)\n",
    "tf.summary.scalar('Validation_Accuracy', accuracy2)\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "step = 0\n",
    "\n",
    "writer = tf.summary.FileWriter(\"logs/pair/%s/\"%(TRAIN_WO_SPEC_GAN), sess.graph)\n",
    "summaries = tf.summary.merge_all()\n",
    "\n",
    "print(\"We are going to train fake detector using ResNet based on triplet loss!!!\")\n",
    "start_lr = lr\n",
    "while (step * batch_size) < max_iter:\n",
    "    epoch1=np.floor((step*batch_size)/glen1)\n",
    "    if (((step*batch_size)%glen1 < batch_size) & (lr==1e-4) & (epoch1 >=3)):\n",
    "        lr /= 10\n",
    "    \n",
    "    if epoch1 <=3:\n",
    "        sess.run([sia_optimizer],  feed_dict={learning_rate: lr})\n",
    "    else:\n",
    "        sess.run([optimizer],  feed_dict={learning_rate: lr})\n",
    "        \n",
    "    if (step % 15000==1) & (step>15000):\n",
    "        save_path = saver.save(sess, \"checkpoints/tf_deepUD_tri_model_iter_%d_for_%s.ckpt\" % (step,TRAIN_WO_SPEC_GAN))\n",
    "        print(\"Model saved in file at iteration %d: %s\" % (step*batch_size,save_path))\n",
    "\n",
    "    if step>0 and step % display_step == 0:\n",
    "        # calculate the loss\n",
    "        loss, acc, summaries_string, sia_val = sess.run([cost, accuracy, summaries, sialoss])\n",
    "        print(\"Iter=%d/epoch=%d, Loss=%.6f, Triplet loss=%.6f, Training Accuracy=%.6f, lr=%f\" % (step*batch_size, epoch1 ,loss, sia_val, acc, lr))\n",
    "        writer.add_summary(summaries_string, step)\n",
    "    \n",
    "    if step>0 and (step % (display_step*20) == 0):\n",
    "        rounds = tlen1 // 1000\n",
    "        #pdb.set_trace()\n",
    "        valacc=[]\n",
    "        vis=[]\n",
    "        tis=[]\n",
    "        for k in range(rounds):\n",
    "            a2, vi, ti = sess.run([accuracy2, tf.argmax(valpred, 1), val_labels])\n",
    "            valacc.append(a2)\n",
    "            vis.append(vi)\n",
    "            tis.append(ti)\n",
    "        tis = np.reshape(np.asarray(tis), [-1])\n",
    "        vis = np.reshape(np.asarray(vis), [-1])\n",
    "        precision=metrics.precision_score(tis, vis) \n",
    "        recall=metrics.recall_score(tis, vis)\n",
    "        \n",
    "        sal, valimg = sess.run([saliency, val_data])\n",
    "        utils.batchsalwrite(valimg, sal, tis, vis, 'saliency_img/%s_Detected_'%(TRAIN_WO_SPEC_GAN))\n",
    "        \n",
    "\n",
    "        print(\"Iter=%d/epoch=%d, Validation Accuracy=%.6f, Precision=%.6f, Recall=%.6f\" % (step*batch_size, epoch1 , np.mean(valacc), precision, recall))\n",
    "\n",
    "  \n",
    "    step += 1\n",
    "print(\"Optimization Finished!\")\n",
    "save_path = saver.save(sess, \"checkpoints/tf_deepUD_tri_model_%s.ckpt\" % (TRAIN_WO_SPEC_GAN))\n",
    "print(\"Model saved in file: %s\" % save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
